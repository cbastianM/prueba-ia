import streamlit as st
import pandas as pd
import google.generativeai as genai
import re

# --- ConfiguraciÃ³n de la PÃ¡gina de Streamlit ---
st.set_page_config(
    page_title="Tutor de EstÃ¡tica con Gemini",
    page_icon="ğŸ—ï¸",
    layout="wide"
)

# --- Funciones Auxiliares ---

@st.cache_data
def load_data():
    """Carga los datos de problemas desde el archivo CSV."""
    try:
        df = pd.read_csv('database/statics_problems.csv')
        # Â¡IMPORTANTE! Ya no convertimos el ID a entero. Se queda como texto.
        # df['id'] = df['id'].astype(int) <-- LÃNEA ELIMINADA
        return df
    except FileNotFoundError:
        st.error("ERROR CRÃTICO: No se encontrÃ³ 'database/statics_problems.csv'.")
        return None

# --- FUNCIÃ“N DE BÃšSQUEDA COMPLETAMENTE REESCRITA ---
def find_exercise_by_string_id(query, df):
    """
    Busca un ejercicio usando un patrÃ³n de texto como "beer 2.43".
    Es flexible con espacios y separadores (puntos o guiones).
    """
    # PatrÃ³n de Regex: busca (beer|hibbeler), seguido de espacios, seguido de (nÃºmero.nÃºmero) o (nÃºmero-nÃºmero)
    # Puedes aÃ±adir mÃ¡s libros a la lista, ej: (beer|hibbeler|meriam|...)
    match = re.search(r'(beer|hibbeler)\s*(\d+[\.\-]\d+)', query, re.IGNORECASE)
    
    if match:
        book_name = match.group(1).lower()
        problem_number = match.group(2).replace('-', '.') # Normalizamos guiones a puntos
        
        # Construimos el ID estandarizado para buscar en el DataFrame
        search_id = f"{book_name} {problem_number}"
        
        # Buscamos el ID exacto en el DataFrame
        result_df = df[df['id'] == search_id]
        
        if not result_df.empty:
            return result_df.to_dict('records')[0] # Devuelve el diccionario del problema encontrado
    
    return None # Si no hay match o no se encuentra el ID, devuelve None


def get_gemini_response(api_key, conversation_history, exercise_data):
    """
    Genera una respuesta de la IA. (Esta funciÃ³n no necesita cambios).
    """
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemma-3-12b-it')
        
        if exercise_data:
            # ... (prompt largo y detallado que ya tenÃ­amos)
            system_context = f"""
            Tu rol es ser un tutor de EstÃ¡tica...
            **REGLAS ESTRICTAS...**
            **DATOS DEL PROBLEMA:**
            - ID: {exercise_data['id']}
            - Enunciado: {exercise_data['enunciado']}
            - Procedimiento: {exercise_data['procedimiento']}
            - Respuesta: {exercise_data['respuesta']}
            """
        else:
            system_context = """
            Tu rol es ser un tutor general de EstÃ¡tica...
            """
        
        full_prompt = system_context + "\n\n---\n\nHistorial: " + "".join([f"{m['role']}: {m['content']}\n" for m in conversation_history])
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        st.error(f"Error al contactar la API de Google Gemini: {e}")
        return None

# --- INICIO DE LA APLICACIÃ“N ---

# InicializaciÃ³n y carga de datos
# ... (cÃ³digo sin cambios)
if 'selected_problem' not in st.session_state:
    st.session_state.selected_problem = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'api_key' not in st.session_state:
    st.session_state.api_key = None
df_problems = load_data()

# Interfaz principal
st.title("ğŸ—ï¸ Tutor de EstÃ¡tica con Google Gemini")
st.markdown("Pide un ejercicio por su nombre y nÃºmero (ej: `explica beer 2.43`)")

# Barra lateral
with st.sidebar:
    st.header("ğŸ”‘ ConfiguraciÃ³n de API")
    # ... (cÃ³digo de API key y VersiÃ³n Pro sin cambios)
    with st.container(border=True):
        st.markdown("#### âœ¨ VersiÃ³n Pro")
        st.write("Desbloquea ejercicios ilimitados, explicaciones avanzadas y soporte prioritario.")
        st.link_button("Conoce los beneficios ğŸš€", "https://www.tu-pagina-de-precios.com")
    st.markdown("---")
    st.header("ğŸ“š Ejercicios Disponibles")
    if df_problems is not None:
        for index, row in df_problems.iterrows():
            # Ahora muestra el ID de texto correctamente
            st.markdown(f"- **ID: {row['id']}** ({row['tema']})")
    else:
        st.error("No se pudieron cargar los ejercicios.")

# Mostrar detalles del problema seleccionado
# ... (cÃ³digo sin cambios)
if st.session_state.selected_problem:
    with st.expander("Detalles del Problema Seleccionado", expanded=True):
        st.markdown("---")
        # ... (muestra detalles)


# Mostrar historial de chat
# ... (cÃ³digo sin cambios)
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


# --- LÃ“GICA DE CHAT ACTUALIZADA ---
if prompt := st.chat_input("Â¿QuÃ© quieres aprender hoy?"):
    if not st.session_state.api_key:
        st.warning("Por favor, ingresa y guarda tu API Key de Google en la barra lateral."); st.stop()

    with st.chat_message("user"): st.markdown(prompt)
    st.session_state.chat_history.append({"role": "user", "content": prompt})

    visual_keywords = ["imagen", "pdf", "manual", "visual", "diagrama", "enlace", "url", "link", "dibujo", "figura", "grÃ¡fico"]
    
    # INTENCIÃ“N 1: Pedir material visual
    if any(keyword in prompt.lower() for keyword in visual_keywords) and st.session_state.selected_problem:
        # ... (cÃ³digo sin cambios)
        prob = st.session_state.selected_problem
        with st.chat_message("assistant"):
            if pd.notna(prob['imagen_url']):
                assistant_response = f"Â¡Claro! AquÃ­ tienes el enlace al material visual del problema **{prob['id']}**: [**Abrir Imagen/PDF**]({prob['imagen_url']})"
                st.markdown(assistant_response)
            else:
                assistant_response = f"Lo siento, el problema **{prob['id']}** no tiene un material visual asociado."
                st.markdown(assistant_response)
        st.session_state.chat_history.append({"role": "assistant", "content": assistant_response})

    # INTENCIÃ“N 2: Seleccionar un problema por su nuevo ID de texto
    else:
        found_exercise = find_exercise_by_string_id(prompt, df_problems)
        
        if found_exercise:
            # Si el ID existe, se carga y se explica
            st.session_state.selected_problem = found_exercise
            
            with st.chat_message("assistant"):
                with st.spinner("Preparando la explicaciÃ³n inicial... ğŸ¤“"):
                    initial_history = [{"role": "user", "content": "ExplÃ­came cÃ³mo resolver este problema paso a paso, usando el formato matemÃ¡tico correcto."}]
                    response = get_gemini_response(st.session_state.api_key, initial_history, st.session_state.selected_problem)
                    if response:
                        st.markdown(response)
                        st.session_state.chat_history = [{"role": "user", "content": prompt}, {"role": "assistant", "content": response}]
                    else: 
                        st.error("No se pudo generar la explicaciÃ³n inicial.")
            st.rerun()
        else:
            # INTENCIÃ“N 3: No se encontrÃ³ un ID, es una pregunta de seguimiento o general
            with st.chat_message("assistant"):
                with st.spinner("Pensando... ğŸ¤”"):
                    response = get_gemini_response(st.session_state.api_key, st.session_state.chat_history, st.session_state.selected_problem)
                if response:
                    st.markdown(response)
                    st.session_state.chat_history.append({"role": "assistant", "content": response})
                else: 
                    st.error("No se pudo obtener una respuesta.")
