# -------------------
# LIBRERAS
# -------------------
import streamlit as st
import google.generativeai as genai
import pandas as pd
import numpy as np
import re

# -------------------
# CONFIGURACIN DE LA PGINA Y API
# -------------------
st.set_page_config(
    page_title="Tu Profesor de Ing. Civil",
    page_icon="",
    layout="centered" # Un layout m谩s enfocado para chat
)

st.title(" Tu Profesor Virtual de Ingenier铆a Civil")
st.markdown("Hazme una pregunta sobre un tema o pide la explicaci贸n de un ejercicio de la base de conocimiento.")

# Cargar la API Key desde los secrets de Streamlit
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=GEMINI_API_KEY)
except (FileNotFoundError, KeyError):
    st.error("锔 No se encontr贸 la GEMINI_API_KEY. Por favor, config煤rala en los secrets de Streamlit Cloud.")
    st.stop()

# -------------------
# BASE DE CONOCIMIENTO (DATOS DENTRO DEL CDIGO)
# -------------------

# @st.cache_resource: Esta funci贸n se ejecuta solo UNA VEZ cuando la app arranca.
# Es perfecto para crear recursos que no cambian, como nuestra base de conocimiento.
@st.cache_resource
def get_knowledge_base():
    """
    Define la base de datos directamente en el c贸digo, la convierte a DataFrame
    y genera los embeddings. Retorna el DataFrame procesado.
    """
    # --- 隆AQU ES DONDE AADES O MODIFICAS TU CONOCIMIENTO! ---
    data = [
        {
            "ID_Ejercicio": "BEER 2.73",
            "Libro": "Beer & Johnston",
            "Tema": "Est谩tica",
            "Contenido": "Para resolver este problema, se debe realizar un Diagrama de Cuerpo Libre (DCL) en la junta B, donde concurren las tres fuerzas. Luego, se aplican las ecuaciones de equilibrio est谩tico. Sumatoria de fuerzas en X (危Fx = 0) y sumatoria de fuerzas en Y (危Fy = 0). Al descomponer las tensiones en sus componentes y resolver el sistema de dos ecuaciones con dos inc贸gnitas (T_AB y T_BC), se obtienen las tensiones en los cables."
        },
        {
            "ID_Ejercicio": "HIBBELER 4.5",
            "Libro": "Hibbeler",
            "Tema": "Estructuras",
            "Contenido": "El objetivo es encontrar la reacci贸n vertical en el apoyo A (Ay). El m茅todo m谩s directo es aplicar una sumatoria de momentos (危M) en el punto B, ya que las reacciones en B no generar谩n momento respecto a s铆 mismas. La ecuaci贸n es: 危M_B = 0. Se considera el momento generado por la carga externa y el momento generado por la reacci贸n Ay. Resolviendo la ecuaci贸n, se despeja el valor de Ay."
        },
        {
            "ID_Ejercicio": "",
            "Libro": "Teor铆a",
            "Tema": "Mec谩nica de Suelos",
            "Contenido": "La consolidaci贸n de un suelo es un proceso lento de reducci贸n de volumen en un suelo saturado de baja permeabilidad (como arcillas) debido a la expulsi贸n gradual del agua de los poros tras un aumento de la carga. La teor铆a de Terzaghi modela este comportamiento asumiendo un flujo de agua unidimensional y un suelo homog茅neo."
        },
        {
            "ID_Ejercicio": "",
            "Libro": "Teor铆a",
            "Tema": "Hidr谩ulica",
            "Contenido": "La Ecuaci贸n de Manning es una f贸rmula emp铆rica fundamental para el c谩lculo de la velocidad media del flujo de agua en un canal abierto que no est谩 bajo presi贸n. La f贸rmula es V = (1/n) * R_h^(2/3) * S^(1/2), donde 'V' es la velocidad, 'n' es el coeficiente de rugosidad de Manning (depende del material del canal), 'R_h' es el radio hidr谩ulico y 'S' es la pendiente del canal."
        }
    ]
    
    df = pd.DataFrame(data)
    
    # Generaci贸n de embeddings
    model_embedding = 'models/embedding-001'
    def get_embedding(text):
        if pd.isna(text) or not str(text).strip(): return [0.0] * 768
        return genai.embed_content(
            model=model_embedding, content=str(text), task_type="RETRIEVAL_DOCUMENT")["embedding"]

    df['Embedding'] = df['Contenido'].apply(get_embedding)
    return df

# -------------------
# LGICA DEL CHATBOT (CEREBRO CON PERSONA DE PROFESOR)
# -------------------

def extract_exercise_id(query):
    """Extrae un ID de ejercicio de la pregunta del usuario."""
    books = ["beer", "hibbeler", "singer", "gere", "chopra", "irving"]
    pattern = re.compile(
        r'\b(' + '|'.join(books) + r')[\s\w\.]*(\d+[\.\-]\d+)\b', re.IGNORECASE)
    match = pattern.search(query)
    if match:
        book_name = match.group(1).upper()
        exercise_num = match.group(2).replace('-', '.')
        return f"{book_name} {exercise_num}"
    return None

def generate_response(query, dataframe):
    """Genera una respuesta con el modelo Gemini y la persona de un profesor."""
    model_generation = genai.GenerativeModel('gemini-1.5-flash-latest')
    
    # ESTRATEGIA 1: B煤squeda por ID de ejercicio (Prioritaria)
    exercise_id = extract_exercise_id(query)
    if exercise_id:
        match = dataframe[dataframe['ID_Ejercicio'].str.strip().str.upper() == exercise_id.upper()]
        if not match.empty:
            context = match.iloc[0]['Contenido']
            libro = match.iloc[0]['Libro']
            prompt = f"""
            Eres un profesor de Ingenier铆a Civil. Tu tarea es explicar la soluci贸n al ejercicio "{exercise_id}" del libro "{libro}".
            Usa el siguiente texto como base para tu explicaci贸n. S茅 claro, did谩ctico y explica el 'porqu茅' de los pasos, como si se lo estuvieras ense帽ando a un estudiante.
            No te limites a transcribir, 隆ense帽a! Basa tu explicaci贸n 煤nicamente en el contexto proporcionado.

            **Contexto de la Soluci贸n:**
            ---
            {context}
            ---

            **Tu explicaci贸n como profesor:**
            """
            response = model_generation.generate_content(prompt)
            return response.text
        else:
            return f"Lo siento, he buscado en mi base de conocimiento pero no tengo informaci贸n sobre el ejercicio '{exercise_id}'. Te recomiendo consultar tu libro de texto."

    # ESTRATEGIA 2: B煤squeda sem谩ntica para preguntas te贸ricas
    query_embedding = genai.embed_content(model='models/embedding-001', content=query, task_type="RETRIEVAL_QUERY")["embedding"]
    
    dataframe['Embedding'] = dataframe['Embedding'].apply(np.array)
    knowledge_embeddings = np.stack(dataframe['Embedding'].values)
    dot_products = np.dot(knowledge_embeddings, query_embedding)
    
    # Umbral de similitud para asegurar relevancia
    similarity_threshold = 0.7 
    if np.max(dot_products) < similarity_threshold:
        return "Lo siento, no he encontrado informaci贸n suficientemente relevante sobre ese tema en mi base de conocimiento actual."

    top_index = np.argmax(dot_products)
    context = dataframe.iloc[top_index]['Contenido']
    
    prompt = f"""
    Eres un profesor de Ingenier铆a Civil. Un estudiante te ha hecho la siguiente pregunta.
    Usa NICA Y EXCLUSIVAMENTE el siguiente texto de contexto para formular tu explicaci贸n.
    Explica el concepto de forma clara, concisa y did谩ctica, como si se lo estuvieras ense帽ando a alguien por primera vez.

    **Contexto Relevante:**
    ---
    {context}
    ---
    **Pregunta del Estudiante:** {query}
    **Tu explicaci贸n como profesor:**
    """
    response = model_generation.generate_content(prompt)
    return response.text

# -------------------
# INTERFAZ DE USUARIO PRINCIPAL
# -------------------

# Carga la base de conocimiento una sola vez
try:
    df_knowledge = get_knowledge_base()
except Exception as e:
    st.error(f"Ocurri贸 un error al inicializar la base de conocimiento: {e}")
    st.stop()

# Inicializa el historial del chat
if 'messages' not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "隆Hola! Soy tu profesor virtual. 驴En qu茅 tema o ejercicio necesitas ayuda hoy?"}]

# Muestra los mensajes del historial
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Acepta la entrada del usuario
if prompt := st.chat_input("Escribe tu pregunta aqu铆..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Genera y muestra la respuesta
    with st.chat_message("assistant"):
        with st.spinner("Consultando mis apuntes..."):
            response = generate_response(prompt, df_knowledge)
            st.markdown(response)
    
    st.session_state.messages.append({"role": "assistant", "content": response})
