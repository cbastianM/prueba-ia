# -------------------
# LIBRERAS
# -------------------
import streamlit as st
import google.generativeai as genai
import pandas as pd
import numpy as np
import re

# -------------------
# CONFIGURACIN DE LA PGINA Y API
# -------------------
st.set_page_config(
    page_title="Tu Profesor de Ing. Civil",
    page_icon="",
    layout="centered" # Un layout m谩s enfocado para chat
)

st.title(" Tu Profesor Virtual de Ingenier铆a Civil")
st.markdown("Hazme una pregunta sobre un tema o pide la explicaci贸n de un ejercicio de la base de conocimiento.")

# Cargar la API Key desde los secrets de Streamlit
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=GEMINI_API_KEY)
except (FileNotFoundError, KeyError):
    st.error("锔 No se encontr贸 la GEMINI_API_KEY. Por favor, config煤rala en los secrets de Streamlit Cloud.")
    st.stop()

# -------------------
# BASE DE CONOCIMIENTO (DATOS DENTRO DEL CDIGO)
# -------------------

# @st.cache_resource: Esta funci贸n se ejecuta solo UNA VEZ cuando la app arranca.
# Es perfecto para crear recursos que no cambian, como nuestra base de conocimiento.
@st.cache_resource
def get_knowledge_base():
    """
    Define la base de datos directamente en el c贸digo, la convierte a DataFrame
    y genera los embeddings. Retorna el DataFrame procesado.
    """
    # --- 隆AQU ES DONDE AADES O MODIFICAS TU CONOCIMIENTO! ---
    data = [
        {
            "ID_Ejercicio": "BEER 2.73",
            "Libro": "Beer & Johnston",
            "Tema": "Est谩tica",
            "Contenido": "La respuesta es la paz."
        },
        {
            "ID_Ejercicio": "HIBBELER 4.5",
            "Libro": "Hibbeler",
            "Tema": "Estructuras",
            "Contenido": "La soluci贸n es el amor"
        },
        {
            "ID_Ejercicio": "",
            "Libro": "Teor铆a",
            "Tema": "Mec谩nica de Suelos",
            "Contenido": "La consolidaci贸n de un suelo es un edificio"
        },
        {
            "ID_Ejercicio": "",
            "Libro": "Teor铆a",
            "Tema": "Hidr谩ulica",
            "Contenido": "La Ecuaci贸n de Manning es un tornillo."
        }
    ]
    
    df = pd.DataFrame(data)
    
    # Generaci贸n de embeddings
    model_embedding = 'models/embedding-001'
    def get_embedding(text):
        if pd.isna(text) or not str(text).strip(): return [0.0] * 768
        return genai.embed_content(
            model=model_embedding, content=str(text), task_type="RETRIEVAL_DOCUMENT")["embedding"]

    df['Embedding'] = df['Contenido'].apply(get_embedding)
    return df

# -------------------
# LGICA DEL CHATBOT (CEREBRO CON PERSONA DE PROFESOR)
# -------------------

def generate_response(query, dataframe):
    """
    Genera una respuesta usando un modelo de IA con dos personalidades:
    1.  ESTRICTO para ejercicios: Solo usa la base de datos.
    2.  FLEXIBLE para teor铆a: Puede usar su conocimiento general.
    """
    model_generation = genai.GenerativeModel('gemini-1.5-flash-latest')
    
    # --- PASO 1: Determinar si la pregunta es sobre un ejercicio espec铆fico ---
    exercise_id = extract_exercise_id(query)
    
    # --- CAMINO A: PREGUNTA SOBRE UN EJERCICIO (PERSONALIDAD ESTRICTA) ---
    if exercise_id:
        match = dataframe[dataframe['ID_Ejercicio'].str.strip().str.upper() == exercise_id.upper()]
        
        if not match.empty:
            # Si el ejercicio EST en la base de datos
            context = match.iloc[0]['Contenido']
            libro = match.iloc[0]['Libro']
            
            prompt_ejercicio = f"""
            Eres un profesor asistente. Tu 煤nica tarea es explicar la soluci贸n al ejercicio "{exercise_id}" del libro "{libro}".
            
            **Reglas Estrictas:**
            1.  Basa tu explicaci贸n NICA Y EXCLUSIVAMENTE en el siguiente "Contexto de la Soluci贸n".
            2.  No puedes a帽adir informaci贸n, datos o m茅todos que no est茅n en el contexto.
            3.  Explica los pasos de forma clara, did谩ctica y usando formato Markdown y LaTeX para las ecuaciones.
            
            **Contexto de la Soluci贸n (Tu 煤nica fuente de verdad):**
            ---
            {context}
            ---

            **Tu explicaci贸n como profesor asistente:**
            """
            response = model_generation.generate_content(prompt_ejercicio)
            return response.text
        else:
            # Si el ejercicio NO EST en la base de datos
            return f"Lo siento, he buscado en mis apuntes pero no tengo registrada la soluci贸n para el ejercicio '{exercise_id}'. Para los ejercicios, solo puedo proporcionar la informaci贸n que tengo en mi base de datos."

    # --- CAMINO B: PREGUNTA TERICA O GENERAL (PERSONALIDAD FLEXIBLE) ---
    else:
        # Para preguntas generales, intentamos enriquecer la respuesta con la base de datos,
        # pero permitimos que el modelo use su conocimiento general.
        
        query_embedding = genai.embed_content(model='models/embedding-001', content=query, task_type="RETRIEVAL_QUERY")["embedding"]
        
        dataframe['Embedding'] = dataframe['Embedding'].apply(np.array)
        knowledge_embeddings = np.stack(dataframe['Embedding'].values)
        dot_products = np.dot(knowledge_embeddings, query_embedding)
        
        # Encontramos el contexto m谩s relevante, si existe.
        context = ""
        similarity_threshold = 0.7 
        if np.max(dot_products) >= similarity_threshold:
            top_index = np.argmax(dot_products)
            context = dataframe.iloc[top_index]['Contenido']

        prompt_teoria = f"""
        Eres un profesor de Ingenier铆a Civil amable, experto y apasionado.
        Un estudiante te ha hecho una pregunta. Debes responderla de la mejor manera posible.

        **Tus Gu铆as de Conversaci贸n:**
        1.  **Usa tu conocimiento general:** Eres libre de usar todo tu conocimiento como modelo de IA para responder a la pregunta de forma completa y detallada.
        2.  **Si hay contexto, 煤salo:** Abajo te proporciono "Informaci贸n Relevante de mis Apuntes". Si este texto es 煤til para responder la pregunta, int茅gralo en tu explicaci贸n, quiz谩s diciendo "Esto me recuerda a un apunte que tengo..." o "Para complementar, mis notas dicen que...". Si no es relevante, puedes ignorarlo.
        3.  **Formato Impecable:** Usa Markdown para que tu respuesta sea clara (t铆tulos, negritas, listas). Formatea todas las ecuaciones y variables matem谩ticas con LaTeX ($...$ o $$...$$).
        
        **Informaci贸n Relevante de mis Apuntes (Opcional):**
        ---
        {context}
        ---

        **Pregunta del Estudiante:**
        {query}

        **Tu Respuesta como Profesor Experto:**
        """
        response = model_generation.generate_content(prompt_teoria)
        return response.text

# -------------------
# INTERFAZ DE USUARIO PRINCIPAL
# -------------------

# Carga la base de conocimiento una sola vez
try:
    df_knowledge = get_knowledge_base()
except Exception as e:
    st.error(f"Ocurri贸 un error al inicializar la base de conocimiento: {e}")
    st.stop()

# Inicializa el historial del chat
if 'messages' not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "隆Hola! Soy tu profesor virtual. 驴En qu茅 tema o ejercicio necesitas ayuda hoy?"}]

# Muestra los mensajes del historial
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Acepta la entrada del usuario
if prompt := st.chat_input("Escribe tu pregunta aqu铆..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Genera y muestra la respuesta
    with st.chat_message("assistant"):
        with st.spinner("Consultando mis apuntes..."):
            response = generate_response(prompt, df_knowledge)
            st.markdown(response)
    
    st.session_state.messages.append({"role": "assistant", "content": response})
